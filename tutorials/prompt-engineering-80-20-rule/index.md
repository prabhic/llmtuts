# Prompt Engineering 80/20 Rule

This folder contains a comprehensive analysis of prompt engineering techniques based on empirical research from 2022-2025, demonstrating which techniques deliver the highest return on investment.

## Contents

### ðŸ“š Main Article
- **[README.md](./README.md)** - The complete research-backed article showing how 20% of prompt engineering techniques deliver 80% of quality improvements

### ðŸŽ¯ Quick Reference
- **[quick-reference.md](./quick-reference.md)** - Practical cheat sheet with code examples and decision frameworks

### ðŸ“Š Metadata
- **[metadata.yaml](./metadata.yaml)** - Article metadata, tags, and citation information

## Key Takeaways

1. **Format beats wordsmithing** - Structure alone can improve performance by 40%
2. **2-3 examples are optimal** - More examples rarely help and often hurt
3. **Temperature 0.0-0.2 for factual tasks** - Single parameter change = 20% accuracy gain
4. **Stop at "good enough"** - Perfect prompts have diminishing returns

## Who Should Read This

- **Engineers** implementing LLM features
- **Product Managers** optimizing AI products
- **Team Leads** allocating engineering resources
- **Developers** learning prompt engineering basics

## Quick Start

For immediate application, read the [quick-reference.md](./quick-reference.md) first, then dive into the full article for detailed evidence and case studies.

## Contributing

Found a quantified case study or research paper on prompt engineering ROI? Please submit a PR with:
- Source citation
- Quantified improvements (percentages, metrics)
- Techniques used
- Model and context

## Citation

```bibtex
@article{kumar2025prompt8020,
  title={The 80/20 Rule of LLM Prompt Engineering: How Minimal Techniques Deliver Maximum Results},
  author={Kumar, Prabhanjan},
  year={2025},
  url={https://github.com/prabhic/llmtuts/tree/main/tutorials/prompt-engineering-80-20-rule}
}
```